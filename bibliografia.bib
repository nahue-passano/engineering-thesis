@misc{amazonwebservices,
  title = {Amazon Web Services},
  author = {{Amazon Web Services}},
  year = {2006},
  howpublished = {\url{https://aws.amazon.com}},
  note = {Consultado el 03/05/2024}
}

@inproceedings{hasanabadi2023mfccgan,
  title={MFCCGAN: A Novel MFCC-Based Speech Synthesizer Using Adversarial Learning},
  author={Hasanabadi, Mohammad Reza and Behdad, Majid and Gharavian, Davood},
  booktitle={ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={1--5},
  year={2023},
  organization={IEEE}
}

@misc{huggingface,
  title = {Hugging Face: The {AI} community building the future},
  author = {Delangue, C. and Chaumond, J and Wolf, T.},
  year = {2016},
  howpublished = {\url{https://huggingface.co/}},
  note = {Consultado el 03/05/2024}
}

@techreport{itu-p800,
  author = {{ITU-T}},
  title = {{ITU-T Recommendation P.800. Mean opinion score (MOS) terminology}},
  year = {1996},
  institution = {{International Telecommunication Union}},
  number = {P.800},
  type = {Recommendation}
}

@techreport{itu-p862,
  author = {{ITU-T}},
  title = {{ITU-T Recommendation P.862. Perceptual evaluation of speech quality (PESQ): An objective method for end-to-end speech quality assessment of narrow-band telephone networks and speech codecs}},
  year = {2001},
  institution = {{International Telecommunication Union}},
  number = {P.862},
  type = {Recommendation}
}

@inproceedings{kalchbrenner2018,
  author = {Kalchbrenner, N. and Elsen, E. and Simonyan, K. and Noury, S. and Casagrande, N. and Lockhart, E. and {et al.}},
  title = {Efficient neural audio synthesis},
  booktitle = {International Conference on Machine Learning},
  year = {2018},
  month = {Julio},
  pages = {2410-2419},
  organization = {PMLR}
}

@article{kong2020,
  author = {Kong, J. and Kim, J. and Bae, J.},
  title = {{Hifi-gan}: Generative adversarial networks for efficient and high fidelity speech synthesis},
  journal = {Advances in Neural Information Processing Systems},
  volume = {33},
  year = {2020},
  pages = {17022-17033}
}

@inproceedings{koluguri2022,
  author = {Koluguri, N. R. and Park, T. and Ginsburg, B.},
  title = {Titanet: Neural model for speaker representation with 1d depth-wise separable convolutions and global context},
  booktitle = {ICASSP 2022-2022 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2022},
  month = {Mayo},
  pages = {8102-8106},
  organization = {IEEE}
}

@inproceedings{kumar2023,
  author = {Kumar, A. and Tan, K. and Ni, Z. and Manocha, P. and Zhang, X. and Henderson, E. and Xu, B.},
  title = {Torchaudio-squim: Reference-less speech quality and intelligibility measures in torchaudio},
  booktitle = {ICASSP 2023-2023 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2023},
  month = {Junio},
  pages = {1-5},
  organization = {IEEE}
}

@inproceedings{lancucki2021,
  author = {Łańcucki, A.},
  title = {FastPitch: Parallel text-to-speech with pitch prediction},
  booktitle = {ICASSP 2021-2021 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2021},
  month = {Junio},
  pages = {6588-6592},
  organization = {IEEE}
}

@inproceedings{leroux2019,
  author = {Le Roux, J. and Wisdom, S. and Erdogan, H. and Hershey, J. R.},
  title = {{SDR}–half-baked or well done?},
  booktitle = {ICASSP 2019-2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2019},
  month = {Mayo},
  pages = {626-630},
  organization = {IEEE}
}

@article{mittag2021,
  author = {Mittag, G. and Naderi, B. and Chehadi, A. and Möller, S.},
  title = {{NISQA}: A deep {CNN}-self-attention model for multidimensional speech quality prediction with crowdsourced datasets},
  journal = {arXiv preprint},
  eprint = {2104.09494},
  year = {2021}
}

@misc{nvidia2023,
  title = {Overview of Zero-Shot Multi-Speaker {TTS} Systems: Top Q\&As},
  author = {{NVIDIA}},
  year = {2023},
  howpublished = {\url{https://developer.nvidia.com/blog/overview-of-zero-shot-multi-speaker-tts-systems-top-qas/}},
  note = {Consultado el 03/05/2024}
}

@inproceedings{radford2023,
  author = {Radford, A. and Kim, J. W. and Xu, T. and Brockman, G. and McLeavey, C. and Sutskever, I.},
  title = {Robust speech recognition via large-scale weak supervision},
  booktitle = {International Conference on Machine Learning},
  year = {2023},
  month = {Julio},
  pages = {28492-28518},
  organization = {PMLR}
}

@article{ren2019,
  author = {Ren, Y. and Ruan, Y. and Tan, X. and Qin, T. and Zhao, S. and Zhao, Z. and Liu, T. Y.},
  title = {Fastspeech: Fast, robust and controllable text to speech},
  journal = {Advances in Neural Information Processing Systems},
  volume = {32},
  year = {2019}
}

@inproceedings{rix2001,
  author = {Rix, A. W. and Beerends, J. G. and Hollier, M. P. and Hekstra, A. P.},
  title = {Perceptual evaluation of speech quality ({PESQ})-a new method for speech quality assessment of telephone networks and codecs},
  booktitle = {2001 IEEE International Conference on Acoustics, Speech, and Signal Processing. Proceedings},
  year = {2001},
  volume = {2},
  pages = {749-752},
  address = {Salt Lake City, UT, USA},
  organization = {IEEE},
  doi = {10.1109/ICASSP.2001.941023}
}

@inproceedings{shen2018,
  author = {Shen, J. and Pang, R. and Weiss, R. J. and Schuster, M. and Jaitly, N. and Yang, Z. and {et al.}},
  title = {Natural {TTS} synthesis by conditioning {WaveNet} on mel spectrogram predictions},
  booktitle = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2018},
  month = {Abril},
  pages = {4779-4783},
  organization = {IEEE}
}

@misc{seabold2010,
  author = {Seabold, S. and Perktold, J.},
  title = {{Statsmodels}: Econometric and statistical modeling with Python},
  year = {2010},
  note = {Python},
  doi = {10.25080/issn.2575-9752}
}

@misc{streamlit,
  title = {Streamlit},
  author = {{Streamlit}},
  year = {2018},
  howpublished = {\url{https://github.com/streamlit/streamlit}},
  note = {Consultado el 03/05/2024}
}

@inproceedings{taal2010,
  author = {Taal, C. H. and Hendriks, R. C. and Heusdens, R. and Jensen, J.},
  title = {A short-time objective intelligibility measure for time-frequency weighted noisy speech},
  booktitle = {2010 IEEE International Conference on Acoustics, Speech and Signal Processing},
  year = {2010},
  pages = {4214-4217},
  address = {Dallas, TX, USA},
  organization = {IEEE},
  doi = {10.1109/ICASSP.2010.5495701}
}

@inproceedings{wan2018,
  author = {Wan, L. and Wang, Q. and Papir, A. and Moreno, I. L.},
  title = {Generalized end-to-end loss for speaker verification},
  booktitle = {2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  year = {2018},
  month = {Abril},
  pages = {4879-4883},
  organization = {IEEE}
}

@inproceedings{wei2018,
  author = {Wei, P. and Peng, K. and Gibiansky, A. and Arik, S. O. and Kannan, A. and Narang, S. and Raiman, J. and Miller, J.},
  title = {Deep Voice 3: 2000-speaker neural text-to-speech},
  booktitle = {International Conference on Learning Representations},
  year = {2018}
}

@article{hardesty2017,
  author = {Hardesty, L.},
  title = {Explained: Neural networks},
  journal = {MIT News Office},
  year = {2017},
}

@article{basheer2000,
  author = {Basheer, I. and Hajmeer, M.},
  title = {Artificial neural networks: fundamentals, computing, design, and application},
  journal = {Journal of Microbiological Methods},
  volume = {43},
  number = {1},
  pages = {3-31},
  year = {2000}
}

@article{hornik1991,
  author = {Hornik, K.},
  title = {Approximation capabilities of multilayer feedforward networks},
  journal = {Neural Networks},
  volume = {4},
  number = {2},
  pages = {251-257},
  year = {1991}
}

@book{chollet2021,
  author = {Chollet, F.},
  title = {Deep Learning with Python},
  edition = {2},
  publisher = {Manning Publications},
  address = {New York},
  year = {2021}
}

@article{sejdic2009,
  author = {Sejdić, E. and Djurović, I. and Jiang, J.},
  title = {Time-frequency feature representation using energy concentration: An overview of recent advances},
  journal = {Digital Signal Processing},
  volume = {19},
  number = {1},
  pages = {153--183},
  year = {2009},
  doi = {10.1016/j.dsp.2007.12.004}
}

@article{coker1976,
  author = {Coker, Cecil H.},
  title = {A Model of Articulatory Dynamics and Control},
  journal = {Proceedings of the IEEE},
  volume = {64},
  number = {4},
  pages = {452--460},
  year = {1976}
}

@inproceedings{seeviour1976,
  author = {Seeviour, P and Holmes, J and Judd, M},
  title = {Automatic Generation of Control Signals for a Parallel Formant Speech Synthesizer},
  booktitle = {ICASSP'76. IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume = {1},
  pages = {690--693},
  year = {1976},
  organization = {IEEE}
}

@inproceedings{olive1977,
  author = {Olive, Joseph},
  title = {Rule Synthesis of Speech from Dyadic Units},
  booktitle = {ICASSP'77. IEEE International Conference on Acoustics, Speech, and Signal Processing},
  volume = {2},
  pages = {568--570},
  year = {1977},
  organization = {IEEE}
}
@article{zen2009,
  author = {Zen, Heiga and Tokuda, Keiichi and Black, Alan W.},
  title = {Statistical Parametric Speech Synthesis},
  journal = {Speech Communication},
  volume = {51},
  number = {11},
  pages = {1039--1064},
  year = {2009}
}

@book{quinn2020,
  author = {Quinn, Joanne},
  title = {Dive into Deep Learning: Tools for Engagement},
  year = {2020},
  address = {Thousand Oaks, California},
  publisher = {},
  pages = {551},
  isbn = {978-1-5443-6137-6},
}


@article{bencomo2022,
  author = {Bencomo, Anadeli},
  title = {{Audioboom: la narrativa hispanoamericana en el formato audiolibro}},
  journal = {Revista chilena de literatura},
  volume = {105},
  pages = {17-44},
  year = {2022},
  month = {Mayo},
  issn = {0718-2295},
  doi = {10.4067/s0718-22952022000100017},
}

@misc{audible,
  title = {Audible},
  author = {{Amazon}},
  year = {1995},
  howpublished = {\url{https://www.audible.com/}},
  note = {Consultado el 03/05/2024}
}

@misc{librofm,
  title = {Libro.fm},
  author = {{Pearson, Mark and Hartung, Carl and Johnson, Nick}},
  year = {2014},
  howpublished = {\url{https://libro.fm/}},
  note = {Consultado el 03/05/2024}
}

@misc{elevenlabs,
  title = {Eleven Labs},
  author = {{Staniszewski, Mateusz and Dąbkowski, Piotr}},
  year = {2022},
  howpublished = {\url{https://elevenlabs.io/}},
  note = {Consultado el 03/05/2024}
}

@article{oord2016,
  author = {van den Oord, Aaron and Dieleman, Sander and Zen, Heiga and Simonyan, Karen and Vinyals, Oriol and Graves, Alex and Kalchbrenner, Nal and Senior, Andrew and Kavukcuoglu, Koray},
  title = {{Wavenet}: A Generative Model for Raw Audio},
  journal = {arXiv preprint arXiv:1609.03499},
  year = {2016}
}

@article{sproat2001,
  author = {Sproat, Richard and Black, Alan W and Chen, Stanley and Kumar, Shankar and Ostendorf, Mari and Richards, Christopher},
  title = {Normalization of Non-standard Words},
  journal = {Computer Speech \& Language},
  volume = {15},
  number = {3},
  pages = {287--333},
  year = {2001}
}


@article{sproat2016,
  author = {Sproat, Richard and Jaitly, Navdeep},
  title = {{RNN} Approaches to Text Normalization: A Challenge},
  journal = {arXiv preprint arXiv:1611.00068},
  year = {2016}
}

@inproceedings{zhang2020,
  author = {Zhang, Junhui and Pan, Junjie and Yin, Xiang and Li, Chen and Liu, Shichao and Zhang, Yang and Wang, Yuxuan and Ma, Zejun},
  title = {A Hybrid Text Normalization System Using Multi-head Self-Attention for Mandarin},
  booktitle = {ICASSP 2020-2020 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages = {6694--6698},
  year = {2020},
  organization = {IEEE}
}

@inproceedings{ge2e2018,
  title={Generalized end-to-end loss for speaker verification},
  author={Li, Wan and Wang, Quan and Papir, Alan and Lopez Moreno, Ignacio},
  booktitle={Proc. IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP)},
  year={2018}
}


@inproceedings{heigold2016end,
  title={End-to-end text-dependent speaker verification},
  author={Heigold, Georg and Moreno, Ignacio and Bengio, Samy and Shazeer, Noam},
  booktitle={Acoustics, Speech and Signal Processing (ICASSP), 2016 IEEE International Conference on},
  pages={5115--5119},
  organization={IEEE},
  year={2016}
}

@article{mfcc,
  author={Abdul, Zrar Kh. and Al-Talabani, Abdulbasit K.},
  journal={IEEE Access}, 
  title={Mel Frequency Cepstral Coefficient and its Applications: A Review}, 
  year={2022},
  volume={10},
  number={},
  pages={122136-122158},
  keywords={Mel frequency cepstral coefficient;Feature extraction;Speech recognition;Emotion recognition;Filter banks;Discrete cosine transforms;Cepstrum;MFCC;speech analysis;cepstrum analysis;feature extraction;indusial analysis},
  doi={10.1109/ACCESS.2022.3223444}}

@inproceedings{tacotron2,
  title={Natural TTS synthesis by conditioning WaveNet on Mel spectrogram predictions},
  author={Shen, Jonathan and Pang, Ruoming and Weiss, Ron J and Schuster, Mike and Jaitly, Navdeep and Yang, Zongheng and Chen, Zhifeng and Zhang, Yu and Wang, Yuxuan and Skerrv-Ryan, Rj and others},
  booktitle={2018 IEEE international conference on acoustics, speech and signal processing (ICASSP)},
  pages={4779--4783},
  year={2018},
  organization={IEEE}
}

@article{tacotron,
  title={Tacotron: Towards end-to-end speech synthesis},
  author={Wang, Yuxuan and Skerry-Ryan, RJ and Stanton, Daisy and Wu, Yonghui and Weiss, Ron J and Jaitly, Navdeep and Yang, Zongheng and Xiao, Ying and Chen, Zhifeng and Bengio, Samy and others},
  journal={arXiv preprint arXiv:1703.10135},
  year={2017}
}

@inproceedings{wavernn,
  title={Efficient neural audio synthesis},
  author={Kalchbrenner, Nal and Elsen, Erich and Simonyan, Karen and Noury, Seb and Casagrande, Norman and Lockhart, Edward and Stimberg, Florian and Oord, Aaron and Dieleman, Sander and Kavukcuoglu, Koray},
  booktitle={International Conference on Machine Learning},
  pages={2410--2419},
  year={2018},
  organization={PMLR}
}

@mastersthesis{sv2tts,
  title={Real-Time Voice Cloning},
  author={Jemine, C.},
  year={2019},
  school={Université de Liège},
  address={Liège, Belgique},
  note={Unpublished master's thesis},
  url={https://matheo.uliege.be/handle/2268.2/6801}
}

@article{bengio2015scheduled,
  title={Scheduled sampling for sequence prediction with recurrent neural networks},
  author={Bengio, Samy and Vinyals, Oriol and Jaitly, Navdeep and Shazeer, Noam},
  journal={Advances in neural information processing systems},
  volume={28},
  year={2015}
}

@article{hifigan,
  title={Hifi-gan: Generative adversarial networks for efficient and high fidelity speech synthesis},
  author={Kong, Jungil and Kim, Jaehyeon and Bae, Jaekyoung},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={17022--17033},
  year={2020}
}

@article{commonvoice,
  title={Common voice: A massively-multilingual speech corpus},
  author={Ardila, Rosana and Branson, Megan and Davis, Kelly and Henretty, Michael and Kohler, Michael and Meyer, Josh and Morais, Reuben and Saunders, Lindsay and Tyers, Francis M and Weber, Gregor},
  journal={arXiv preprint arXiv:1912.06670},
  year={2019}
}

@article{librispeech,
  title={MLS: A Large-Scale Multilingual Dataset for Speech Research},
  author={Vineel Pratap and Qiantong Xu and Anuroop Sriram and Gabriel Synnaeve and Ronan Collobert},
  journal={ArXiv},
  year={2020},
  volume={abs/2012.03411}
}

@inproceedings{crowdsourcedLATAM,
    title = "Crowdsourcing {L}atin {A}merican {S}panish for Low-Resource Text-to-Speech",
    author = "Guevara-Rukoz, Adriana  and
      Demirsahin, Isin  and
      He, Fei  and
      Chu, Shan-Hui Cathy  and
      Sarin, Supheakmungkol  and
      Pipatsrisawat, Knot  and
      Gutkin, Alexander  and
      Butryna, Alena  and
      Kjartansson, Oddur",
    editor = "Calzolari, Nicoletta  and
      B{\'e}chet, Fr{\'e}d{\'e}ric  and
      Blache, Philippe  and
      Choukri, Khalid  and
      Cieri, Christopher  and
      Declerck, Thierry  and
      Goggi, Sara  and
      Isahara, Hitoshi  and
      Maegaard, Bente  and
      Mariani, Joseph  and
      Mazo, H{\'e}l{\`e}ne  and
      Moreno, Asuncion  and
      Odijk, Jan  and
      Piperidis, Stelios",
    booktitle = "Proceedings of the Twelfth Language Resources and Evaluation Conference",
    month = may,
    year = "2020",
    address = "Marseille, France",
    publisher = "European Language Resources Association",
    url = "https://aclanthology.org/2020.lrec-1.801",
    pages = "6504--6513",
    abstract = "In this paper we present a multidialectal corpus approach for building a text-to-speech voice for a new dialect in a language with existing resources, focusing on various South American dialects of Spanish. We first present public speech datasets for Argentinian, Chilean, Colombian, Peruvian, Puerto Rican and Venezuelan Spanish specifically constructed with text-to-speech applications in mind using crowd-sourcing. We then compare the monodialectal voices built with minimal data to a multidialectal model built by pooling all the resources from all dialects. Our results show that the multidialectal model outperforms the monodialectal baseline models. We also experiment with a {``}zero-resource{''} dialect scenario where we build a multidialectal voice for a dialect while holding out target dialect recordings from the training data.",
    language = "English",
    ISBN = "979-10-95546-34-4",
}

@misc{reaper,
  author       = {{Cockos Incorporated}},
  title        = {REAPER: Digital Audio Workstation Software},
  year         = {2004},
  url          = {https://es.wikipedia.org/wiki/REAPER},
  note         = {Consultado el 03/05/2024}
}

@inproceedings{whisper,
  title={Robust speech recognition via large-scale weak supervision},
  author={Radford, Alec and Kim, Jong Wook and Xu, Tao and Brockman, Greg and McLeavey, Christine and Sutskever, Ilya},
  booktitle={International Conference on Machine Learning},
  pages={28492--28518},
  year={2023},
  organization={PMLR}
}

@inproceedings{crepe,
  title={Crepe: A convolutional representation for pitch estimation},
  author={Kim, Jong Wook and Salamon, Justin and Li, Peter and Bello, Juan Pablo},
  booktitle={2018 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)},
  pages={161--165},
  year={2018},
  organization={IEEE}
}

@misc{coquitts,
  author = {Coqui.ai},
  title = {TTS: Text-to-Speech for all},
  year = {2024},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/coqui-ai/TTS}},
  note = {Accessed: 2024-06-15}
}

@article{fastspeech2,
  title={Fastspeech 2: Fast and high-quality end-to-end text to speech},
  author={Ren, Yi and Hu, Chenxu and Tan, Xu and Qin, Tao and Zhao, Sheng and Zhao, Zhou and Liu, Tie-Yan},
  journal={arXiv preprint arXiv:2006.04558},
  year={2020}
}

@article{pitchprediction,
  title={Accurate short-term analysis of the fundamental frequency and the harmonics-to-noise ratio of a sampled sound},
  author={Boersma, Paul},
  journal={IFA Proceedings},
  pages={97--110},
  year={1993}
}

@article{adam,
  title={Adam: A method for stochastic optimization},
  author={Kingma, Diederik P and Ba, Jimmy},
  journal={arXiv preprint arXiv:1412.6980},
  year={2014}
}

@article{attention,
  title={Attention is all you need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, {\L}ukasz and Polosukhin, Illia},
  journal={Advances in neural information processing systems},
  volume={30},
  year={2017}
}

@article{adamw,
  title={Decoupled weight decay regularization},
  author={Loshchilov, Ilya and Hutter, Frank},
  journal={arXiv preprint arXiv:1711.05101},
  year={2017}
}

@article{valle,
  title={Neural codec language models are zero-shot text to speech synthesizers},
  author={Wang, Chengyi and Chen, Sanyuan and Wu, Yu and Zhang, Ziqiang and Zhou, Long and Liu, Shujie and Chen, Zhuo and Liu, Yanqing and Wang, Huaming and Li, Jinyu and others},
  journal={arXiv preprint arXiv:2301.02111},
  year={2023}
}

@article{xtts,
  title={XTTS: a Massively Multilingual Zero-Shot Text-to-Speech Model},
  author={Casanova, Edresson and Davis, Kelly and G{\"o}lge, Eren and G{\"o}knar, G{\"o}rkem and Gulea, Iulian and Hart, Logan and Aljafari, Aya and Meyer, Joshua and Morais, Reuben and Olayemi, Samuel and others},
  journal={arXiv preprint arXiv:2406.04904},
  year={2024}
}

@article{tortoise,
  title={Better speech synthesis through scaling},
  author={Betker, James},
  journal={arXiv preprint arXiv:2305.07243},
  year={2023}
}

@inproceedings{GPT2,
  title={Language Models are Unsupervised Multitask Learners},
  author={Alec Radford and Jeff Wu and Rewon Child and David Luan and Dario Amodei and Ilya Sutskever},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:160025533}
}